2023 - 3 -13

腾讯客户端实习

![image-20240313153352129](C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20240313153352129.png)

# c++基础

**1 const作用**

面向过程： const修饰的常量，放在代码段，定义时必须初始化，且仅本文件可见

面向对象：const成员变量只能通过初始化列表进行初始化，const成员方法在调用const对象时不会修改

传参：const形参可以接收任意实参，且const对象只能调用const方法

**2 static关键字的作用**

面向过程角度

* 修饰==全局变量、函数==，修饰过后，全局变量和函数只能在当前文件可见，是因为在编译生成的符号表中，符号作用域从g（global）变为l（local）
* 修饰==局部变量==，初始化不为0的，放在data段，未初始化和初始化为0，放在bss段
* 局部变量本身不产生符号，通过ebp-偏移量访问，static后，产生local符号

面向对象角度

* 修饰成员变量，变为全局共享，类里面定义，类外初始化
* 修饰成员方法，不再产生this指针，可以通过作用域调用，且static方法只能调用static变量
* static成员方法不能背const 和 virtual修饰，const是因为不调用成员变量，也不会修改，virtual是因为static与类有关，与实例无关，没有多态可言

**3 volatile关键字的作用**

告诉编译器不要对该变量进行优化，因为该变量的值可能会在编译器优化的作用下发生变化，例如==多线程环境==中，变量可能会被其他线程修改。

在多线程编程中，`volatile`关键字用于确保线程之间对共享变量的可见性。当一个变量被声明为`volatile`时，每次对该变量的读取都会直接从内存中读取，而不是从缓存中读取，同时每次对该变量的写入也会直接写入到内存中，而不是先写入到缓存。这样可以确保当一个线程修改了该变量的值后，其他线程能够立即看到这个修改，而不会因为缓存而导致数据不一致的情况发生。

需要注意的是，`volatile`只能保证可见性，不能保证原子性。如果需要确保多线程环境下对变量的读取和写入是原子操作的，还需要使用其他机制，比如使用`mutex`（互斥锁）或`atomic`类型等。

 

**4 mutable关键字**

mutable作用于==类的成员变量==，即便在const成员函数中，也可以对其进行修改

```cpp
class MyClass {
public:
    mutable int x;
    MyClass(int val) : x(val) {}
    
    void modifyX() const {
        x++; // 即使在const成员函数中，x也可以被修改
    }
};
```



注意和`const_cast`进行区分，这个作用于const修饰的变量和volatile属性修饰的变量



**5 explict关键字**

作用域==类的构造函数==，修饰的构造函数不能再发生隐式类型转换，必须通过显示构造



**3 c++如何调用c语言？**

c 和 c++在编译过程中的==函数名修饰规则==不同，c是根据==函数名==表示，c++会根据==函数名==和==参数==命名，因此编译c语言需要在`extern "C"{}`之中

同样的原因，c++导致相同函数名，参数不同的函数在==符号表==内的名字不同，这也是==函数重载==的原理



**4 c 和 c++的区别**

1面向对象，使用设计模式      2 引用    3函数重载    4 new和delete   5  异常处理   6 模板  7 STL



**5 const int* p  和 int* cosnt p的区别**

常量指针：const int* p = &a; 即指针的解引用是常量的，即*p不变，但是p = b;

指针常量 int * constp = &a;  指针本身是不变的，解引用可以改变*p = 20;



**6 指针和引用区别**

指针是变量，开辟内存，存指向变量的地址，引用是别名，与变量共享地址

指针可以为空，且可以修改，引用必须初始化，且只能定义一次

引用的本质是指针常量（int* const），是c++的语法糖

指针和引用都可以作为参数传递，减少对变量的拷贝，但是传指针本质上也是值传递，对指针的内容，也就是地址做了拷贝，若在函数内部修改了指针的内容，不会影响函数外部的指针，但是函数内部修改指针指向的位置，即变量，就会修改变量

传引用不存在拷贝，传的就是变量本身



**7 什么时候使用指针传参和引用传参？**

当需要==返回函数内部的通过new出来的局部变量==时候，通过传入指针，保存局部变量的值，但是后续注意释放，内存泄漏

但是也是因为传入指针需要额外开辟空间，对于==对栈内存敏感==的函数（递归）优先使用引用

==类对象的传递==也是使用引用

|              | 只使用传递过来的值，而不对值进行修改 | 需要修改传递过来的值 |
| ------------ | ------------------------------------ | -------------------- |
| 内置数据类型 | 按值传递（小型结构）                 | 指针传递             |
| 数组         | 指针传递                             | 指针传递             |
| 结构         | 指针或引用（较大的结构）             | 指针或引用           |
| 类、对象     | 引用传递                             | 引用传递             |

**8 如何判断大小端存储？**

* 电脑： 小端法

高位存高地址、低位存低地址

* 网络 大端

<img src="C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20240314170616566.png" alt="image-20240314170616566" style="zoom: 67%;" />



使用强制类型转换解决

```cpp
#include <iostream>
using namespace std;
int main()
{
    int a = 0x1234;
    //由于int和char的长度不同，借助int型转换成char型，只会留下低地址的部分
    char c = (char)(a);
    if (c == 0x12)
        cout << "big endian" << endl;
    else if(c == 0x34)
        cout << "little endian" << endl;
}

```



**9 函数调用栈过程，参数or返回值先入栈？**

1. 保存当前环境的==系统状态==，便于恢复

1. 首先，调用函数时，将调用者==函数的返回地址==压入栈中，以便在函数调用结束后返回到调用者函数的适当位置。
2. 接下来，将调用者函数的==参数==依次压入栈中，通常是从右往左的顺序。
3. 然后，在调用的函数内部执行时，会在栈上分配空间用于==局部变量==、函数内部的==临时变量==以及其他需要的数据。
4. 函数执行结束后，==返回值==会被放入调用者函数期望的位置（通常是寄存器或者内存），然后函数返回到调用者函数处，将栈上的数据恢复到调用前的状态，包括返回地址和参数等。

因此，在函数调用过程中，参数变量会先于返回值入栈。这是因为参数需要在函数内部使用，而返回值通常是在函数执行结束后才需要。



**10 static_cast为什么安全？**

1. 在不引入额外开销的情况下进行类型转换
2. 显示的注明类型转换，避免隐式类型转换造成的问题
3. 保持了const的属性，转换前后的const属性不变



## 类

**1 c++的this指针是干什么用的？**

this实际上是成员函数的一个形参，在调用成员函数时候，会将对象的地址作为实参传递给this，

this是局部形参，只能用在成员函数的内部，只有调用成员函数时才给this传值



**2 什么情况下发生拷贝构造？**

* 用一个实例化对象去初始化另一个对象
* 通过值传递方式传入对象
* ==vs==下值传递方式返回一个对象， g++下不会调用拷贝构造

**1 继承的赋值兼容规则**？

派生类对象可以赋值给基类对象、基类对象指针、基类对象引用，这个过程中会发生切片

反过来，若是基类对象想赋值给派生类对象指针，则需要通过dynamic_cast进行判断，若基类指针是指向派生类的对象，则可以赋值成功，否则失败



**2 派生类的构造函数和析构函数是怎么样的？**

* 派生类对象必须调用基类的==构造方法==初始化基类的成员变量，若基类没有默认的构造函数，则必须在派生类的初始化列表中显示调用
* 派生类对象必须调用基类的==拷贝构造==和==运算符重载==给基类的成员变量赋值
* 派生类的==析构函数==会在执行完毕后自动调用基类的析构函数

<img src="C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20240313164545853.png" alt="image-20240313164545853" style="zoom:33%;" />

* 当派生类和基类由同名的成员方法时，派生类会隐藏掉基类的方法和变量，可以通过基类的作用域调用



**3 继承和组合区别是什么？**

两种都是类的复用技术

继承允许根据基类的实现来定义派生类，基类的内部对派生类可见，耦合度很高，两个类有关系则优先使用，实现多态也要使用

==组合==是将基类封装在另一个类的内部，基类的内部对其不可见，耦合度很低，代码维护性好



**4 继承的好处是什么？**

* 实现了代码复用
* 可以通过继承，在基类的内部给所有派生类保留同一的纯虚函数接口，派生类进行重写，可以实现多态，即通过基类指针访问不同派生类对象的同名覆盖方法





## 内存管理

**1 new和delete，什么时候用new[]申请的内存，可以用delete释放**？

new的作用是 申请开辟内存空间 +申请失败抛异常 +  调用对象的构造函数

operator new  是 malloc + 申请内存失败抛异常

 malloc： 申请失败return 0 

delete： 释放内存空间 + 调用对象的析构函数

operatpr delete 和 free 区别不大

== 对于自定义类型，如果提供了析构函数，当使用new[]申请空间时，除了申请对象外，额外申请4个字节记录对象的申请个数，必须调用delelte[]释放==

其余情况下，使用new[]申请，可以用delete ptr释放

**2 虚拟地址空间**

<img src="C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20240313161217327.png" alt="image-20240313161217327" style="zoom:67%;" />





.bss： 未初始化、初始化为0的==全局变量==，未初始化、初始化为0的==静态变量==

* 不在可执行未见中，由系统初始化，初始化时，部分bss段清0

.data ：初始化不为0的==全局变量==和==静态变量==

.text : 存放程序执行代码、只读==常量==、==字符串常量==、==类的成员函数==，==静态成员变量、静态成员函数==

* data text在可执行文件中，系统从可执行文件中加载

```cpp
int bss_1;// 未初始化的全局变量，bss段
int bss_2 = 0;// 初始化为0的全局变量，bss段
int data_1 = 1;// 初始化非0的全局变量，data段
int main() {
    static int bss_3;// 未初始化的静态局部变量，bss段
    static int bss_4 = 0;// 初始化为0静态局部变量，bss段
    static int data_2 = 1;// 初始化非0静态局部变量，data段
}
```



**3 如何防止内存泄漏**

内存泄漏不是指物理内存上的泄漏，而是指不适用的内存没有释放，导致对其的控制

常见的两种

* 堆内存泄漏：指用户通过new malloc operator new等申请的内存资源使用完毕后，没有用delelte free释放，，导致无法使用
* 在多态中，基类析构函数没有声明为虚函数，导致派生类调用析构时没有调用到基类析构，导致基类成员变量没有被释放
* 系统资源泄漏：套接字、文件描述符等使用韩币后没有释放

对长期运行的程序危害比较大，比如操作系统、后台服务等

linux下的内存检测工具：valgrind

windows下常见的工具有 CRT



**4 什么时候出现访问越界？**

越界即系统给你分配了固定的内存，你访问到了外部的内存即越界

* 访问数组、vector会越界
* 字符串处理没有带0，会越界
* 在dynamic_cast中，派生类指针指向基类对象失败，解引用会越界



**开辟内存方式**

1. `malloc`（Memory Allocation）：
   - 函数签名：`void* malloc(size_t size);`
   - 作用：用于分配指定大小的堆内存，返回一个指向分配内存的指针。如果分配成功，返回一个合法的指针；如果分配失败，返回`NULL`。

2. `calloc`（Contiguous Allocation）：
   - 函数签名：`void* calloc(size_t num_elements, size_t element_size);`
   - 作用：用于分配指定数量和大小的连续块内存，返回一个指向分配内存的指针。所有分配的内存都被初始化为零。如果分配成功，返回一个合法的指针；如果分配失败，返回`NULL`。

3. `realloc`（Reallocate Memory）：
   - 函数签名：`void* realloc(void* ptr, size_t new_size);`
   - 作用：用于重新调整先前分配的内存块的大小。通常用于扩展或缩小内存块。它接受一个先前分配的内存块指针和新的大小作为参数，返回一个指向重新分配内存的指针。如果分配失败，返回`NULL`。如果`ptr`为`NULL`，则`realloc`的行为等同于`malloc`。

## STL

**1 讲一下空间配置器**

空间配置器主要是给容器使用的

* 一是把内存开辟和对象构造分开，把内存释放和对象析构分开，因为有一些场景下是需要先开辟空间，在后续执行过程中在创建对象，在析构对象后，也不需要释放内存空间
* 二是解决==频繁向系统申请小块内存==的问题，容易造成资源泄露
* 原理：配置器有两级构成，以128字节为界限将内存块分为大内存和小内存，大内存块的申请释放由一级配置器进行管理，对mallo和free与申请失败抛异常进行封装，和operator new差不多
* 二级配置器用来管理小内存，底层是一个哈希桶，内存申请的大小是从8字节到128字节
* 为什么是8个字节，因为下方挂的是内存块，为表示64位下的地址空间，采用8字节



**2 vector和list的区别**

vector支持随机访问，优先级队列就是基于vector构建的适配器

list支持高效的增删改查

## 数据结构

![image-20240313180924748](C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20240313180924748.png)



## c++11

**1 智能指针**



**2 初始化列表**

功能：可以通过初始化列表指定成员变量的初始化方式，在类中，成员变量的初始化顺序与其声明的顺序一致，与初始化列表内的顺序无关

底层：`myvector(std::initializer_list<T> il)`,std指定初始化列表容器，用来接收值

`std::initializer_list ilt = { 10, 20, 30 }`





# 网络

## 一 HTTP

### 1. 长轮询和短轮询是什么？

不断轮询是一种简单的客户端-服务器通信方式，客户端周期性地发送HTTP请求到服务器以检查是否有新的数据。

1. **客户端请求**：客户端发送一个HTTP请求到服务器。
2. **服务器响应**：服务器接收到请求并==立即返回==响应（无论是否有新数据）。
3. **等待间隔**：客户端==等待==一段时间（如几秒钟）后，重复步骤1。

- 实现简单，客户端和服务器逻辑都较为简单。

- 低效：大量的HTTP请求会给服务器带来高负载。
- 高延迟：客户端只能在间隔时间后才会收到新数据，不适合对实时性要求高的应用。

长轮询是一种改进的轮询方式，客户端发送请求到服务器后，如果没有新数据，服务器会保持连接一段时间，直到有新数据或连接超时。

1. **客户端请求**：客户端发送一个HTTP请求到服务器。
2. **服务器保持连接**：如果没有新数据，服务器保持连接而不立即返回响应。
3. **服务器响应**：当有新数据时，服务器立即返回响应；如果长时间没有新数据，服务器返回超时响应。
4. **客户端处理并重发请求**：客户端处理响应后立即发送新请求。

- 减少了无效请求，提高了效率。
- 相对实时性较好，因为服务器可以在有新数据时立即返回响应。

- 对服务器资源消耗较大，因为需要保持大量的长时间连接。
- 实现复杂度高于短轮询。

### 2 socket和websocket有什么区别？

| 特性       | Socket                                     | WebSocket                                         |
| ---------- | ------------------------------------------ | ------------------------------------------------- |
| 协议层     | 底层传输协议（TCP/UDP）                    | 应用层协议，基于TCP                               |
| 连接建立   | TCP：三次握手；UDP：无连接                 | 基于HTTP握手，然后升级为WebSocket，只在刚开始使用 |
| 通信方式   | TCP：面向连接、可靠；UDP：无连接、不可靠   | 全双工通信                                        |
| 数据传输   | 二进制或文本数据                           | 二进制或文本数据                                  |
| 保持连接   | TCP：保持连接；UDP：无连接                 | 连接保持打开，直到显式关闭                        |
| 实现复杂度 | 需要处理连接管理、数据传输、错误处理等细节 | 相对简单，通过WebSocket API处理通信               |
| 使用场景   | 底层网络通信、需要高控制的场景             | 实时应用、需要双向通信的Web应用                   |
| 标准和支持 | 通用，几乎所有编程语言和操作系统都支持     | 现代浏览器和服务器都支持，Web应用使用方便         |
| 延迟       | TCP：较低；UDP：最低                       | 较低，适合实时应用                                |

- **Socket**是底层的网络通信机制，提供了对传输层协议（TCP/UDP）的直接控制，适合需要高控制的低级通信场景。
- **WebSocket**是一个应用层协议，提供了在单个TCP连接上实现全双工通信的能力，特别适合Web应用中的实时双向通信需求。

### 3 http和tcp的keepalive

|      | http                                                         | tcp                                                     |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------- |
| 名称 | http长连接                                                   | tcp保活机制                                             |
| 作用 | 延长TCP连接的时间                                            | 判断TCP连接是否断开                                     |
| 原理 | 没有一段提出断开连接，则tcp一直保持。但是设置时间，超时未发送数据则断开连接 | 超时，==内核==里的 TCP 协议栈发送探测报文，决定是否断开 |
| 实现 | 头部字段`connection：Keep-Alive`                             | ` socket` 接口设置 `SO_KEEPALIVE`                       |
| 优点 | 1 节约资源   2 允许客户端发送一组数据，服务器按顺序返回      | 节约资源                                                |
| 缺点 | 发送一组数据时，服务器出错，阻塞后续的客户端数据【队头阻塞】 |                                                         |

### 4 http报文格式

* 发送报文

 1. 请求行

    `GET /index.html HTTP/1.1`

| 字段       | 作用     |
| ---------- | -------- |
| 请求方法   | get post |
| `host`     | url      |
| `http`版本 | 1.1      |

2. 请求头

| 字段             | 作用                   |
| ---------------- | ---------------------- |
| `User-Agent`     | 浏览器厂家             |
| `Accept`         | 客户端可识别的数据格式 |
| `Content-Length` | 附加请求的数据字节     |

3. 空行

   发送回车符，表示请求头结束。解决tcp粘包问题

4. 数据

| 字段             | 作用         |
| ---------------- | ------------ |
| `Content-Type`   | 数据格式     |
| `Content-Length` | 发送数据字节 |

### 5 常用字段



![image-20240802111136469](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408021111540.png)

### 5 http的缓存技术

* 对于某些重复提交的http请求，我们会将 请求-响应 缓存到本地，下次访问时直接从本地缓存获取，而不经过服务器

1. 强制缓存，通过`响应头`中加 `cache-control`字段

   * 第一次浏览器向服务器发送请求，服务器返回响应，加上`cache-control`过期时间，写入缓存
   * 第二次请求，先与本地的过期时间比较，过期则再次向服务器请求，更会缓存的过期时间

2. 协商缓存，两种实现方式，未命中强制缓存，启用协商缓存

   I 基于唯一标识资源（优先级高），请求头：`if-None-match`， 响应头：唯一标识资源`ETag`

   * 若缓存`cache-control`过期，将缓存的ETag字段与服务器资源ETag对比，若无修改，则返回 304， 访问缓存
   * 若ETag不同，资源发生修改，则直接服务器返回200，更新缓存

   II 基于最后修改时间：请求头：`if-modified-since`，响应头：`last-modified`

   *  若没有ETag字段，则检查使用last-modified字段
   * 若缓存`cache-control`过期，比较缓存与服务器的最后修改时间
   * 时间相同，则返回304， 读取缓存
   * 时间不同，则服务器返回 200，更新缓存

* 无法被缓存的请求
  1. HTTP信息头中包含Cache-Control:no-cache，pragma:no-cache（HTTP1.0），或Cache-Control:max-age=0等告诉浏览器不用缓存的请求
  2. 需要根据Cookie，认证信息等决定输入内容的动态请求是不能被缓存的
  3. 经过HTTPS安全加密的请求
  4. POST请求无法被缓存
  5. HTTP响应头中不包含Last-Modified/Etag，也不包含Cache-Control/Expires的请求无法被缓存
     



<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408011742382.png" alt="image-20240801174226942" style="zoom:67%;" />

### 6 get和post的区别

| get                                                 | post                                       |
| --------------------------------------------------- | ------------------------------------------ |
| 提交请求，向服务器获取资源                          | 根据请求，修改服务器资源                   |
| 参数在url中，浏览器限制url的长度，且要求格式为ASSIC | 参数在报文body中，浏览器不限长，不限格式   |
| 安全：不修改服务器资源。 幂等：多次请求的结果相同   | 不安全：修改资源  不幂等：请求结果可能不同 |
| 可以被缓存、加书签                                  | 不能被缓存、加书签                         |

### 7 http优缺点

| 优点   | 具体                                                         |
| ------ | ------------------------------------------------------------ |
| 简单   | 报文格式header + body，值采用key + value形式                 |
| 灵活   | url，状态码， 头字段组成允许用户自定义                       |
| 可扩展 | 位于第七次，下层可自定义，http1.1、http2.0使用tcp，http3.0使用udp |

| 缺点                                         | 解决                                                         |
| -------------------------------------------- | ------------------------------------------------------------ |
| 无状态记录，无法处理连续的有关联的请求       | cookie，记录客户端信息，用于连续通信                         |
| 明文传输、不验证对方身份、不验证信息的正确性 | https，加入ssl/tls层                                         |
| 通信：请求-应答，一次操作断开连接            | 长连接，一方没有断开，则不断开，超时无消息发送，字自动断开   |
| 管道通信、队头阻塞，http1.1无法解决          | http2.0引入stream，一条stream阻塞，不会影响另外一条stream的发送 |

### 8 http断开重连

比如：下载文件，网络断开，恢复后仍能继续下载而不是重新下载

要保证HTTP连接在中断后可以恢复到之前的位置，可以使用“断点续传”技术。这项技术常用于下载大文件、上传文件、流媒体播放等需要持久连接的场景。以下是实现这一功能的关键点：

服务器

1. **支持Range请求头**：服务器必须支持`Range`请求头，以便客户端可以请求特定范围的字节。例如，`Range: bytes=500-999`表示请求从第500字节到999字节的数据。
2. **返回206状态码**：服务器应该返回HTTP 206 Partial Content状态码，表示这是部分内容，而不是整个资源。
3. **Content-Range响应头**：服务器在响应中使用`Content-Range`头来指示返回的字节范围，例如`Content-Range: bytes 500-999/1234`。

浏览器

1. **记录下载进度**：客户端在下载文件时记录已经接收到的字节数。
2. **发送Range请求**：在连接中断后，客户端使用`Range`请求头重新发起请求，请求从上次中断的位置开始的字节。
3. **合并数据**：将新请求返回的数据与之前接收的数据合并。











## 二 HTTPS

### 1 作用

解决http不安全的缺点

| http缺点              | https解决            |
| --------------------- | -------------------- |
| 明文传输 - 窃听风险   | 加密数据             |
| 不验证信息 - 篡改风险 | 哈希算法 +  数字签名 |
| 不验证对方 - 冒充风险 | 身份证书             |





## 三 TCP

### 0 tcp\udp对比

* 运行在计算机上的进程通过端口号来区分，16bit标识，0~ 65535

  | 类型 | UDP                              | TCP                    |
  | ---- | -------------------------------- | ---------------------- |
  |      | 支持一对一，一对多               | 一对一                 |
  |      | 面向报文                         | 面向字节流             |
  |      | 无连接                           | 面向链接               |
  |      | 不安全                           | 安全                   |
  |      | 向上层提供无连接、不可靠传输服务 | 面向连接的可靠传输服务 |
  |      | 视频、会议等实时                 | 文件传输               |

  #### 0.1 基本术语
  
  | 属于     | 含义                                                         | 作用                                              |
  | -------- | ------------------------------------------------------------ | ------------------------------------------------- |
  | `RTT`    | 指发送数据包并接收到ACK所需的时间，用于调整TCP重传超时和拥塞控制策略。 | 1 动态调整RTO   2 拥塞控制                        |
  | `MSL`    | 一个TCP报文段在网络中的最大生存时间，常设置为30s 或 2min     | 1 清除就旧连接  2 TIME_WAIT状态                   |
  | `时间戳` | tcp option字段，用于提高计算RTT的精度                        | 1 精确测量RTT  2 防止序列号绕回  3 丢弃超时数据包 |
  | `RTO`    | 超时重传时间，根域RTT波动计算                                |                                                   |
  
  

![image-20240328154625330](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures@main/img/image-20240328154625330.png)

![image-20240314192809279](C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20240314192809279.png)

### 1 重传机制

#### 1.1 超时重传

利用定时器,当发送方发送数据超过RTO(超时重传时间),则再次发送数据

RTO设置略大于RTT(往返时延)

1. RTO小,则会导致没有丢包就重发数据,导致阻塞.会发送多余的重复数据,浪费资源
2. RTO大,导致网络存在多余的空闲时间

问题:超时周期过长

#### 1.2 快速重传

当收到三次联系的ACK应答帧,触发重传机制

解决:发送方丢包的问题

缺点: 发送方丢失多个包,是重传一个,还是重传所有?

1个: 当丢了多个包时,三个ack触发一次包重传,在需要3个ack才能触发下一个包重传,太耗时

所有: 全部重传,则导致发送重复包

#### 1.3 SACK

选择性确认(select ack)

在tcp报文的 = 选项= 字段添加 SACK字段,记录接收方已经接收到的包

若ACK确认序列号 < SACK的值,说明有包丢失

触发三次ack重传,发送丢失包

#### 1.4 D-SACK

告诉发送方哪些数据发送重复

同样在SACK字段, 记录已经接收到的包

解决: 

1. 接收方的ack确认丢失, 发送方超时后,发送数据帧, 接收方返回sack记录数据一重复,表面是上个ack丢失
2. 网络阻塞,导致发送方数据阻塞. 接收方连续三次ack发起重传, 接收方接收数据. 当上一个数据网络恢复后被接收方接收,则sack记录数据重复,说明是网络阻塞

### 2 滑动窗口

传统tcp通信: 1次发送数据, 收到ack后, 再次发送数据, 收到ack

滑动窗口: 发送方可以发送的,没有收到ack确认的发送数据最大个数

由接收方决定窗口大小, tcp的窗口大小字段,表示接收方能处理的最大数据量

接收方窗口大小 和 发送方窗口大小 约等于

### 3 流量控制

1、tcp通信，发送1个请求，返回一个ack，一来一回，通信效率慢

2、引入窗口（发送窗口、接收窗口），即无需ack确认，可以发送一组tcp报文段、

3、但是不能无脑发送数据，导致处理不过来，超时重传，浪费网络性能

4、提出流量控制机制

![image-20240815160349756](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408151603865.png)

![image-20240815160409076](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408151604183.png)

### 4 拥塞控制

### 5 FIN报文发送方式

| 发送FIN方式  | 方式                 |
| ------------ | -------------------- |
| `closed()`   | 暴力关闭读写，不优雅 |
| `shutdown()` | 控制关闭一端，优雅   |

| `shutdown()`参数      | 解释           | 缓冲区                                              | FIN    |
| --------------------- | -------------- | --------------------------------------------------- | ------ |
| `shutdown(socket, 0)` | 关闭读端       | 全部丢弃读缓存数据，对server发送的消息回执ack并丢弃 | 不发送 |
| `shutdown(socket, 1)` | 关闭写端       | 半关闭连接，发送缓冲区内容全部发送后，发送FIN       | 发送   |
| `shutdown(socket, 2)` | 关闭读端和写端 | 各操作依次                                          | 发送   |

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408141719308.jpg" alt="2dff104a2c381a04706dff2c080bca2" style="zoom: 25%;" />

![image-20240816101742426](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408161017526.png)

1、shutdown关闭读端，当server发送数据给clinet，client会回执==RST报文==，关闭连接

2、shutdown关闭写段，则发送==FIN报文==，走四次挥手，断开tcp连接

【当关闭写端后，在二三次挥手中，由于网络阻塞，FIN报文比数据包先到达，clent会怎么处理？】

答：正常server的顺序是：发送完数据包后，调用close()发送FIN报文

若FIN先到达，则是乱序包，client将FIN放入乱序队列（红黑树）中，继续接收下面的数据，仍处于`FIN_wait2`

接收到新数据后，先判断乱序队列中，是否能有序

有序则执行乱序队列包，无序则将数据包放入乱序队列

直到顺序处理到FIN包，进入三次挥手



### 6 TCP优化

#### 6.0 常用的机制

| 机制             | 作用                        | 字段       |
| ---------------- | --------------------------- | ---------- |
| `tcp_syncookies` | 跳过半连接队列，解决syn攻击 | 携带cookie |
| `tcp_fast_open`  | 跳过三次握手进行通信        | cookie     |
| ` tcp_tw_reuse`  | time_wait端口复用           | 开启时间戳 |
| ``               |                             |            |
| ``               |                             |            |



1. 三次握手优化
2. 四次挥手优化
3. 提高通信效率

#### 6.1 握手优化

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408131725435.png" alt="image-20240813172511344" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408131722437.png" alt="image-20240813172231076" style="zoom: 67%;" />

* 客户端优化

  | 客户端优化        | 原因                                 | 系统默认 |
  | ----------------- | ------------------------------------ | -------- |
  | 减少syn的重传次数 | 减少因为网络波动，等待不断重传的时间 | 默认5次  |

  

* 服务端优化

  | 服务端优化                     | 原因                            | 系统默认 |
  | ------------------------------ | ------------------------------- | -------- |
  | 增大syn队列（半连接队列）      | 避免因为队列满而无法创建连接    |          |
  | 减少syn + ack的重传次数        | 减少超时等待时间，直接断开      | 5次      |
  | 增大accpet（全连接队列）的大小 | 避免从syn队列建立好的连接被丢弃 |          |
  |                                |                                 |          |

* 绕过三次握手

  当应用层协议发送时候，需要先建立tcp连接

  以http为例，在第三次握手后携带get请求，之后服务器返回data，因此，http一次消息需要一个RTT

  <img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408140917592.png" alt="image-20240814091724511" style="zoom:50%;" />

  优化：linux提供 `tcp fast open`机制，通过携带cookie提高tcp连接速度，减少了一个RTT

  第一次tcp正常三次握手连接，client获取cookie

  第二次连接使用`tcp fast open`, 第一次握手携带 syn + cookie + get， 服务器判断cookie有效，则返回

  syn + ack 和 data。客户端接收data，第三次握手返回ack确认

  <img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408140926952.png" alt="image-20240814092638859" style="zoom:50%;" />

#### 6.2 挥手优化

| 主动关闭方优化                   | 解释                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| 调整发送FIN超时次数              |                                                              |
| `FIN_WAIT2`(close关闭)           | 1. shutdown关闭，半连接可读，持续存活时间久   2 closed全连接关闭，存活时间端，设置存活时间久，用于等待server的FIN |
| `TIME_WAIT`                      | （2MSL = 1min）                                              |
| 1、增大处于`timewwait`的个数上限 | 当timewait的连接超过最大个数时，直接关闭                     |
| 2 复用`timewait`连接             | 创建新连接时复用，注意是在client的connect()调用，对server无效 |
| 3、设置`closed`行为              | 默认是发送FIN，修改为RST，跳过四次挥手，直接关闭连接         |

| 被动关闭方优化                   | 解释                        |
| -------------------------------- | --------------------------- |
| 调整发送FIN报文的次数            |                             |
| 处于close_wait状态连接数过多原因 | 应用层没有调用close关闭连接 |



### 7 TIME_WAIT端口复用

当一条 tcp 连接进入time_wait状态时，由于资源被占用，下一条相同四元组的连接无法被创建

端口复用：开启 tcp_tw_reuse + tcp_timestamps

TIME_WAIT的作用：

1、防止历史连接被下一个相同的四元组连接接收。在2MSL的时间内，上一条连接的数据包都会自然小时，再出现的数据包一定是新连接的

2、防止第四次挥手的ACK报文丢失，对端无法关闭。

【端口复用为什么默认关闭？】【为什么需要TIME_WAIT?】

1、虽然通过时间戳可以丢弃大部分的历史数据包，但是RST历史数据包不能被丢弃，可能被下一个相同四元组连接接收

2、无法防止第四次挥手ACK丢失。



  ### 8 挥手状态连接数过多

  在TCP连接关闭过程中，四次挥手对应的状态转换有助于确保数据在连接关闭之前能正确传输。FIN_WAIT1、FIN_WAIT2、CLOSE_WAIT、LAST_ACK这四个状态各自有不同的意义。如果在这些状态中的连接数过多，通常是某些网络或系统问题的表现。下面是每个状态的详细分析，以及可能导致连接数过多的原因：

  #### 1. FIN_WAIT1状态
  当一方主动关闭连接时（通常是客户端），它会发送一个`FIN`报文段，并进入`FIN_WAIT1`状态。此时，该方等待对方的`ACK`确认。

  - **网络延迟或丢包**：网络不稳定，导致发送的`FIN`报文段或对应的`ACK`丢失或延迟，导致连接无法及时进入下一个状态。
  - **对方没有及时响应**：被动关闭的一方可能处理速度较慢或资源不足，导致没有及时发送`ACK`确认。
  - **资源耗尽**：系统资源（如CPU、内存）耗尽，导致处理网络请求和状态转换的速度变慢。

  #### 2. FIN_WAIT2状态
  - `FIN_WAIT1`状态下，主动关闭连接的一方在收到对方的`ACK`确认后，进入`FIN_WAIT2`状态。此时，主动关闭的一方等待对方发送`FIN`报文段。

  - **对方未发送`FIN`**：被动关闭的一方（通常是服务器）由于各种原因没有及时发送`FIN`报文段。这可能是因为对方还在处理剩余的数据传输，或者在处理完成后未能正确关闭连接。
  - **长时间保持连接**：某些应用协议可能会在长时间保持连接（如某些HTTP/1.0或长连接模式），导致连接在`FIN_WAIT2`状态停留较久。
  - **资源不足**：对方服务器资源紧张（如线程池耗尽），导致不能及时处理和关闭连接。

  #### 3. CLOSE_WAIT状态
  - 被动关闭的一方在接收到对方的`FIN`报文段后，会发送`ACK`确认，此时进入`CLOSE_WAIT`状态。然后，它等待应用层主动关闭连接并发送`FIN`。

  - **应用层没有及时关闭连接**：最常见的原因是==应用层没有及时调用`close()`函数来关闭连接==，导致连接长时间停留在`CLOSE_WAIT`状态。这可能是因为程序设计不当或资源泄露问题。
  - **资源耗尽**：服务器资源紧张导致处理关闭请求的速度减慢，无法及时完成连接的关闭。

  #### 4. LAST_ACK状态
  - 在`CLOSE_WAIT`状态下，被动关闭的一方在发送`FIN`后，进入`LAST_ACK`状态，等待最后一个`ACK`确认。

  - **网络延迟或丢包**：最后一个`FIN`报文段或`ACK`报文段在网络中丢失或延迟，导致连接无法从`LAST_ACK`状态结束。
  - **对方未及时发送`ACK`**：主动关闭连接的一方由于网络问题或资源不足，没有及时发送`ACK`确认，从而导致连接在`LAST_ACK`状态停留较久。
  - **资源耗尽**：系统资源不足，导致处理`ACK`的速度变慢，导致大量连接堆积在`LAST_ACK`状态。

  

### 9 TCP粘包

| TCP                                                          | UDP                                      |
| ------------------------------------------------------------ | ---------------------------------------- |
| 面向字节流                                                   | 面向报文段                               |
| 传输时，os将消息分为多组TCP报文段                            | 传输时，os不会对用户消息进行拆分         |
| 1个用户消息   !=  1个用户报文                                | 1个用户消息 == 1个udp报文段， 插入队列中 |
| TCP ==粘包==：当两个消息的某部分内容被分到同一 TCP 报文，接收方无法确定边界，无法划分一个消息 | 读取1个队中节点就是1个udp报文            |

如何解决粘包？

1、固定长度的消息 ，接收方接收到指定大小极为一个消息（死板）

2、特殊字符作为边界： 如http使用 回车 + 换行 区分边界

3、自定义消息结构：设置字段标识data的长度，后面紧跟data

### 10 初始序列号不同

【为什么每次创建TCP连接，初始的序列号都要不同呢？】

答：为了防止历史连接被下一个相同四元组的连接所接收

虽然time_wait阶段可以让历史连接都被丢弃，但是当异常断开连接时候，并未走四次挥手

设置不同的初始化序列号，本质上修改接收窗口的范围，当历史连接不在接收窗口内，会被丢弃

【序列号回绕怎么解决？】

答：序列号在tcp头中有32位，当数据量发送很大的时候，旧连接也可能在接收窗口内

接收端无法根据序列号大小判断新老数据

通过`时间戳`解决，时间戳标志一个tcp报文段，按照递增顺序，当接收到的报文段时间戳小于上一个，则判断为历史连接，丢弃



### 11 阻止历史连接被接收

1、 三次握手

2、 四次挥手中的TIME_WAIT设置为2 x MSL

3、创建新连接随机初始化序列号

### 12 SYN报文被丢弃

【什么时候clent发送的syn报文会被server丢弃？】

1、server的半连接队列满了

2、server的全连接队列满了

3、上一个相同四元组的连接仍处在TIME_WAIT状态，系统资源不够，无法创建新连接

### 13 半连接和全连接

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408160912927.png" alt="image-20240816091200819" style="zoom:67%;" />

半连接队列：哈希表

全连接队列：链表

【全连接队列溢出，如何处理连接？】

一共两种策略

1、server直接丢弃掉client发送的ack

​	此时客户端处于established状态，客户端发送消息，没有回应，超时重发。

​	若全连接队列一直满，则最后超时关闭连接

​	若重发过程中，全连接队列有空位，则因为请求中含有ack消息，仍旧成功建立连接

2、server发送RST报文，直接关闭该条TCP连接

【如何增大全连接队列的大小？】

全队列的大小 = min( somaxconn, backlog)，取最小值

【半连接队列溢出，如何处理连接？】

1、半连接队列满，没有启动tcp_syncookies，丢弃

2、全连接队列满，且存在没有重传【syn+ack】的连接，则丢弃

3、

【如何增加半连接队列的大小？】

1、内核存在一个参数指定半连接队列大小的最大值

2、实际半连接队列大小和全连接大小有关

3、实际半连接队列大小 =` （最大半连接数 > 全连接数）？ 2 * 全连接数 ： 2 * 最大半连接数`

【syn攻击是什么？如何解决？】

答：syn攻击就是不断向server发送syn报文段，却不回复第三次握手的ack，导致半连接队列溢出，无法创建新的连接

解决:

* 1、开启tcp_syncookies，三个档次

机理：客户端发送syn报文，server计算一个cookie，通过syn+ack发送给客户端，客户端回复ack，server校验cookie合法，建立连接

| 选项 | 作用                   |
| ---- | ---------------------- |
| 0    | 关闭                   |
| 1    | 当半连接队列满时，生效 |
| 2    | 一直生效               |

* 2、 增大半连接队列大小
* 3、减少syn+ack的重传次数，由于syn攻击时有大量的syn_recv的连接在重传消息。超时结束，断开连接，因此可以提供断开连接的频率



### 14 已连接的server收到syn报文

【处于established的服务端收到客户端发的SYN报文，会发生什么？】

client与server正常连接，但是client宕机了，开机后重新连接，发送syn请求连接。

1、若四元组不同，则创建新的连接

2、若四元组相同，则关闭连接

* clinet发送： syn + 随机seq
* server回执： 期望的ack + seq
* client接收：发现ack不是期望的，则发送RST报文，关闭连接

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408141642906.png" alt="image-20240814164217821" style="zoom: 67%;" />

【如何关闭一条tcp连接？】

1、杀死进程 （不优雅）

2、client向server发送一个SYN报文，server回执期望的ack

​      client用期望的ack构建一个合法的RST报文，server收到后关闭连接

​	如果发送seq不合法（不是server期望的）的RST报文，会被直接丢弃掉



### 15于time_wait收到syn报文

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408150953489.png" alt="image-20240815095356396" style="zoom:50%;" />

1、判断syn是否合法

合法：syn的序列号 和 时间戳 均大于 clinet（此时作为服务端）期望的seq和时间戳

2、合法syn： client跳过time_wait, 进入syn_receive阶段，回执syn+ack，进入三次握手

3、不合法syn：回执上一个ack，client收到ack判断不是期望的，则回执RST报文

4、server收到RST报文，默认情况下直接关闭连接，但是可以通过调整内核参数，丢弃RST，继续time_wait,



### 16 TCP连接异常情况

| 异常     | 变化                                                    |
| -------- | ------------------------------------------------------- |
| 网线拔掉 | 内核存在，不影响内核中tcp_struct结构，仍是establish状态 |
| 进程崩溃 | 内核仍存在，进程崩溃，内核发送FIN报文，走四次挥手       |
| 主机宕机 | 内核不存在，另一端无法检测主机状态，其仍是establesh状态 |
| 主机恢复 | 内核恢复，tcp_struct结构体不存在，回执RST报文，结束TCP  |

* 结合发送数据、tcp保活机制

1. 网线拔掉

   * 不开启保活机制、无数据发送，对端永远保持ESTABLESH状态
   * 开启保活机制，定时发送探测报文，无响应则超时重传

   * 若另一端发送数据，无法收到ACK，超时重传
   * 重传过程中，若连接上网线，则继续通讯；否则超时结束，tcp断开

2. 进程崩溃

   * 内核主动发送FIN报文，四次挥手结束TCP

3. 主机宕机（与断开网线一致，但是连接上后的情况不同）

   * 不开启保活机制、无数据发送，对端永远保持ESTABLESH状态，客户端和服务端的 TCP 连接状态将会一直保持存在
   * 开启保活机制，定时发送探测报文，无响应则超时重传

   * 若另一端发送数据，无法收到ACK，超时重传

4. 主机恢复

   * 内核恢复，但tcp_struct结构体不存在，回执RST报文，结束TCP



### 17 TCP缺点

1、升级困难。TCP协议升级基于内核，因此需要内核升级，但是市场上的内核升级缓慢。

2、建立连接延迟。必须要三次握手后，还需要经过四次TLS握手，才能建立https连接。且TLS加密在应用层，无	法对TCP头部加密，不安全

3、队头阻塞问题。tcp数据流保证是完整、有序的，当某个协议包丢失时，即使收到后面的包也无法读取

4、网络迁移困难。4G切换WIFI，需要切换四元组，重新建立连接

### 18 UDP实现可靠连接

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408151654352.png" alt="image-20240815165402250" style="zoom:50%;" />

|          | TCP                                  | QUIC                                     |
| -------- | ------------------------------------ | ---------------------------------------- |
| 三次握手 | 同步seq 和 ack                       | 同步 packet number                       |
| 可靠性   | 有序确认                             | 乱序确认                                 |
| 完整性   | 超时重传（同一seq）                  | 超时重传（N严格递增）                    |
| 有序性   | seq + ack                            | streamID + offest                        |
| 流量控制 | 接收窗口处理完有序数据后，才向前滑动 | 给并行stream均分配滑动窗口，解决队头阻塞 |
| 拥塞控制 | 慢启动+拥塞避免+快充穿+快恢复        | 搬运TCP                                  |

【1 为什么N要严格递增？】

答：TCP重传相同的seq容易造成歧义，收到的ack不能判断是阻塞的报文还是重传的报文，进而影响RTT、RTO的计算

因此,重传的N严格递增，可以更加精确计算RTT

【2 N不同，如何判断重传的包与之前一致？】

通过frame内的streamID + offest保证有序性和一致性

【3 QUIC的滑动窗口有何不同？】

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408151702366.png" alt="image-20240815170214195" style="zoom:67%;" />

不同的stream流可以并发的发送数据到内核缓存；

不同的stream流设置各自独立的滑动窗口，一个steam阻塞不会影响其他的stream

【4 如何实现迁移连接？】

从4G切换到WIFI，TCP由于四元组发生变化，导致重新建立TCP连接

QUIC通过连接ID标识客户端和服务端，只要ID不变，就可以继续使用连接

### 19 端口重复

1、TCP 和 UDP  可以共用一个端口

2、相同四元组的TCP 不能共有一个端口

3、服务器不能监听同一个相同四元组

### 20 没有listen/accept

【1 server没有listen，建立连接吗？】

答：可以

server没有listen时，客户端connect发送syn报文，server回复RST报文，断开连接

但是可以建立客户端自链接，客户端与客户端连接

正常tcp连接中，listen()后内核创建半连接队列和全连接队列存放TCP连接，通过accept()获取连接

TCP子连接中，客户端connect()后，将四元组信息放入内核全局hash中，经过回环，再次从hash中获取四元组，建立连接



【3 server没有accept，能建立连接吗？】

答：可以

三次握手在accept之前已经建立，accept只是从全连接队列中取出已建立的tcp连接

### 21 TCP三次挥手

【什么时候TCP四次挥手，可以转变为三次挥手？】

答：在server接收到FIN报文，进入到close_wait状态，==没有数据要发送== 以及 打开了==TCP延迟确认机制==（默认打开）

【什么是TCP延迟确认机制】

当发送ACK报文时候，如果没有携带报文，就比较浪费性能，因为也用了TCP20个字节的头字段

因此，设计出TCP延迟确认机制

1、当发送携带数据的ACK报文，就会直接发送

2、 当发送没有携带数据的ACK报文，就会延迟发送确认帧，延迟时间可以自己设定

3、当延迟发送期间，再次收到对端发送的数据，无论ACK是否携带信息，都直接发送

### 22 序列号和确认号变化

序列号：

1、初始序列号随机

2、序列号seq标识：该TCP报文的数据段中第一个字节在整个数据流中的位置

确认号：

1、期望获得的下一个序列号

变化计算：

【序列号】= 自己发送的上一个报文序列号 + len 

【确认号】= 对方发送的报文的序列号 + len

注意：ACK报文len = 0;  SYN\FIN报文len = 1;

| client                                     | server                              |
| ------------------------------------------ | ----------------------------------- |
| 三次握手                                   |                                     |
| SYN【seq = x】                             |                                     |
|                                            | SYN+ACK【seq = y, ack = x + 1】     |
| ACK【seq = x + 1,  ack = y + 1】           |                                     |
|                                            |                                     |
| 数据发送（10字节数据）                     |                                     |
| PSH + ACK 【seq = x + 1 + 0, ack = y + 1】 | 与三次握手保持一致                  |
|                                            | ACK【seq = y + 1, ack = x +1 + 10】 |
|                                            |                                     |
| 四次挥手                                   |                                     |
| FIN【seq = x + 1 + 10, ack = y + 1】       | 与上一个ACK保持一致                 |
|                                            | ACK【seq = y + 1, ack = x+11 + 1】  |
|                                            | FIN【seq = y + 1, ack = x + 12】    |
| ACK【seq = x+12, ack = y+2】               |                                     |
|                                            |                                     |

### 23 TCP一定不丢包吗

tcp只是保证了运输层不丢包，但是不能保证应用层不丢包

比如tcp发送数据到对方内核缓冲区后，运输层已经执行完成，应用层读取内核缓冲区数据时，可能由于网络波动，造成丢包。此时，需要在应用层设计规则，避免丢包



















# 操作系统

## 1 进程、线程、协程

### 1.1 PCB、进程状态、调度

操作系统对进程进行管理，实际上是将进程控制块PCB放入链表中，进行增删改查

```cpp
struct task_struct{
    // pid
    // PRI NI 优先级
    // task_state_array  进程状态
    // mm_struct  进程地址空间
}
```

进程状态的本质：进程的pcb放入不同的队列

* 执行态：pcb放入cpu管理的任务执行队列中，放入即为执行态
* 阻塞态：进程需要外设资源，没有即阻塞，将pcb从执行队列放入外设管理的wait等待队列
* 挂起态：进程在阻塞态的时候，仍浪费内存，os将其置换到磁盘之中

linux下通过结构体进行管理

![image-20240320144553504](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures@main/img/image-20240320144553504.png)



**2 多级反馈队列调度算法**

--用于处理cpu管理的任务执行队列中的待执行进程的先后顺序调度

1. 先来先服务，利于长作业进程，短作业可能会饿死
2. 短作业优先，不利于长作业
3. 最短剩余时间悠闲，比较进程还需要多少时间片，最短的执行
4. 优先级调度，linux中的优先级通过PCB中的PRI(priority) 和 NI(nice) 控制，用户可以设置NI的值来改变优先级，范围【-20，19】
5. 时间片轮转，过长不利于进程的实时性，过短造成大量上下文切换，浪费性能
6. 多级反馈队列，优先级与时间片的结合，进程没有执行完则放入下一个队列，每一个队列有优先级，第一层最高，每个队列内按时间片轮转控制
   * 进程在进入待调度的队列等待时，首先进入[优先级](https://baike.baidu.com/item/优先级/5643121?fromModule=lemma_inlink)最高的Q1等待。
   * 首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次[优先级队列](https://baike.baidu.com/item/优先级队列/6737671?fromModule=lemma_inlink)中的进程。例如：Q1,Q2,Q3三个队列，[当且仅当](https://baike.baidu.com/item/当且仅当/7689242?fromModule=lemma_inlink)在Q1中没有进程等待时才去调度Q2，同理，只有Q1,Q2都为[空时](https://baike.baidu.com/item/空时/389840?fromModule=lemma_inlink)才会去调度Q3。
   * 对于同一个队列中的各个进程，按照FCFS分配时间片调度。比如Q1队列的[时间片](https://baike.baidu.com/item/时间片/6525414?fromModule=lemma_inlink)为N，那么Q1中的作业在经历了N个时间片后若还没有完成，则进入Q2队列等待，若Q2的时间片用完后作业还不能完成，一直进入下一级队列末尾，直至完成。
   * 在最后一个队列QN中的各个进程，按照[时间片轮转](https://baike.baidu.com/item/时间片轮转/7256857?fromModule=lemma_inlink)分配时间片调度。
   * 在低[优先级](https://baike.baidu.com/item/优先级/5643121?fromModule=lemma_inlink)的队列中的进程在[运行时](https://baike.baidu.com/item/运行时/3335184?fromModule=lemma_inlink)，又有新到达的作业，此时须立即把正在运行的进程放回当前队列的[队尾](https://baike.baidu.com/item/队尾/53401782?fromModule=lemma_inlink)，然后把[处理机](https://baike.baidu.com/item/处理机/128842?fromModule=lemma_inlink)分给高优先级进程。换而言之，任何时刻，只有当第1~i-1队列全部为空时，才会去执行第i队列的进程（抢占式）。特别说明，当再度运行到当前队列的该进程时，仅分配上次还未完成的时间片，不再分配该队列对应的完整时间片

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures@main/img/image-20240320165427807.png" alt="image-20240320165427807" style="zoom: 50%;" />

### 2 父子进程

在 Linux 操作系统中，当父进程通过 `fork()` 系统调用创建子进程时，子进程会继承父进程的虚拟地址空间，包括 `mm_struct` 和页表。然而，尽管它们在初始时看起来相同，但子进程的执行会有所不同，原因如下：

1. **写时复制（Copy-On-Write, COW）**：
   - 当 `fork()` 被调用时，子进程会共享父进程的内存页，直到有一个进程尝试写入这些页。这种机制被称为写时复制。
   - 一旦任何进程（父进程或子进程）尝试写入共享的内存页，内核会创建该页的副本，并将写入操作重定向到新的副本。这意味着，尽管父子进程最初共享相同的页表，实际的物理内存页在写入后会有所不同。
   - 这种机制确保了父进程和子进程的内存彼此独立，不会互相影响。
2. **进程控制块（PCB）和 CPU 寄存器**：
   - 每个进程都有自己的进程控制块（PCB），其中包含进程的状态信息、寄存器内容、程序计数器等。
   - 在 `fork()` 调用后，子进程会从父进程的 PCB 复制一份，并且在内核返回到用户态之前，内核会将子进程的程序计数器设置为 `fork()` 调用的返回地址。
   - 因此，父进程和子进程在用户态代码中的执行路径是独立的，尽管它们最初共享相同的内存内容和地址空间。
3. **文件描述符**：
   - 子进程会继承父进程的文件描述符，这意味着子进程可以访问父进程打开的文件。但它们的文件描述符表也是独立的修改时不会互相影响。

### 3 进程/线程通信

| 进程通信   | 详细                                                         | 适用                                         |
| ---------- | ------------------------------------------------------------ | -------------------------------------------- |
| 管道       | 分为匿名管道、命名管道；不适合频繁发送数据、开销大；         | 父子进程的简单通信                           |
| 消息队列   | 本质是保存在内核中的消息链表，消息可以被存储，任意时间读取，且消息有序，不适合发送大数据（redis实现） | 可靠消息传递，消息顺序重要、任意时间读取数据 |
| 共享内存   | 不同进程通过虚拟地址映射同一块物理地址，多进程下的同步问题   | 高效通信、大数据传输                         |
| 信号       | 处理异常情况下的进程 kill -9，==异步通信机制==，在⼀个进程中通知另⼀个进程发⽣了某种事件从⽽实现进程 通信 |                                              |
| 同步机制： |                                                              |                                              |
| 信号量     | 实现（共享内存）进程的互斥和同步PV操作                       |                                              |
| socket     | 跨网络进程通信                                               |                                              |
| 串口通信   | 位传输、点对点、跨设备（主机和外设间的通信）                 |                                              |

* 管道

  1. 分为匿名管道、有名管道。匿名管道用完即销毁，有名管道提前创建，进程只要使用文件，就可以通信

  2. 基于文件的流式通信，以字节流在管道内传输，通过操作系统进行内核传输

  3. 适用于两个进程之间通信，匿名：常用于父子进程、相关性进程，有名：不相关进程

  4. 优势：流式传输，不需要显示的同步机制

     劣势：传输通过操作系统内核，效率低。管道满会被阻塞。

* 共享内存

  1. 多个进程访问1块共享内存

  2. 基于内存的通信，直接在空间读写，不需要经过内核。

  3. 优点：高效大规模数据传输，直接访问内存，效率高

     缺点：多个进程访问，需要显示同步机制（信号量、互斥锁），实现复杂

![image-20240722114251698](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202407221142752.png)

| 线程通信                                 | 具体                             |
| ---------------------------------------- | -------------------------------- |
| 共享进程内的全局变量或堆内存中的数据结构 | 多线程访问一个类的实例的成员变量 |
| 主要线程互斥问题                         |                                  |







### 4 进程退出

* 退出方式：
  1. exit 和 return : exit返回控制器交给系统，return返回将控制权交给调用函数
  2. exit 和 abort： exit正常退出，abort异常退出
* 多进程退出顺序
  1. 父进程先退出，子进程为孤儿进程，被init进程收养
  2. 子进程先退出，父进程没有调用wait收回状态，子进程为僵尸进程
* 资源释放顺序
  1. 关闭文件描述符：打开的文件、socket、管道
  2. 释放内存：包括堆、栈、地址空间
  3. 结束PCB：释放pcb，包括状态信息、寄存器内容、pc计数器
  4. 信号处理：向等待该进程结束的其他进程发送sigchild信号（父进程wait）
  5. 更新进程表：进程表中该进程条目删除
  6. 通信资源释放：信号量、消息队列、共享内存等

### 5 线程互斥

| 方式     | 原理                                                         |
| -------- | ------------------------------------------------------------ |
| 互斥锁   | mutex、lock_guard<mutex>、shared_lock<mutex>                 |
| 条件变量 | condition_varible cond_   、wait、 wait_for 、notify_one，允许等待某个条件的发生 |
| 原子操作 |                                                              |
| 信号量   | 多维互斥锁                                                   |



### 3 多线程

1. **进程与线程的区别**

* 一个进程通过fork创建子进程时，os把父进程的页表复制一份给子进程，此时，虚拟地址空间不同，物理内存相同。当子进程对空间进行写入时，基于写时复制原则，会重新映射物理内存到页表，实现不同进程的隔离

  <img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408051100815.png" alt="image-20240805110005544" style="zoom:50%;" />

* 一个进程通过vfork或clone创建子进程的时候，会直接共享父进程的资源和虚拟地址空间，资源计数加一，因此，父子进程共享部分资源和虚拟地址、页表，此时子进程被称作线程

* 进程、线程都拥有不同的状态

* 进程是资源分配单位，线程是cpu调度单位

* 线程的优势体现在：并发现高、时间开销、空间开销小

* 具体体现在：创建、销毁、调度。进程创建和销毁需要管理pcb资源等，线程共享部分资源和虚拟地址，只用管理寄存器，线程栈等私有资源，开销较小

  进程的切换需要保存cpu寄存器、程序计数器到PCB中，在读取下一个进程的pcb、涉及到切换页表等时间消耗高的操作。

  同一个进程内部的线程只需要管理私有的寄存器和栈等。开销小

* 线程的缺点：c++中的一个线程崩溃，导致所有线程（整个进程）崩溃。java则不会；

* 原因：c++中非法访问内存，os发送信号让进程奔溃。java中，拦截了os发送的信号，执行自定义信号，防止崩溃

2. **多线程的好处，只有单核多线程有意义吗？**

* 充分利用cpu的性能、减少cpu的空闲时间，提高并发量
* 加快用户的相应时间
* 不同的任务交付给不同的线程，实现代码模块化、优化简单化
* 单核多线程是通过给不同的进程分发时间片，使其宏观上是并发的



3. **线程切换栈会保留哪些？**

 进程是操作系统中资源分配和调度的基本单位，它拥有独立的地址空间和一组资源，所以进程切换时候需要保存的信息比较多

1. 将cpu寄存器和pc程序计数器保存在pcb中 （pc程序计数器、sp栈指针、状态寄存器、通用寄存器）

* 将pcb移动到切换状态的列表中
* 读取下一个进程的pcb内容，涉及到页表切换，耗时较大

线程是进程的执行单位，同一进程下的线程共享进程的地址空间和资源，但是每个线程有自己的执行栈和局部变量

* 首先是和进程一样，保存cpu的寄存器状态：pc、sp 通用寄存器、状态寄存器
* 线程id、线程 状态等
* 保存线程独自的栈指针，用来保存局部变量
* 如果进程给线程提供了空间来保存信息，这些空间也需要保存下来

---------



4. **线程数为什么要预先定义？**

* 不同的应用场景可能需要的线程数目不同，比如说cpu密集型任务需要的线程数较少，io型线程需要的线程数较多
* 线程的数目并不是越多越好，线程会占用一定的系统资源，比如说内存和cpu时间片，所以具体的线程数目需要在项目执行前就考虑好
* 如果在项目执行的过程中频繁的创建和销毁线程，会浪费大量的成本，极大影响效率，因此我们都是提前规划好线程的数目并且采用线程池，极大提高程序的性能。

5. **进程切换为什么比线程切换慢？**

* 自身上下文切换
* 进程切换设计虚拟内存的切换

### 3 进程死锁

1. **死锁的四个必要条件？**

​	① 互斥条件：1个资源每次只能被一个进程执行

​	② 请求与保持：一个进程因为等待资源而阻塞的时候，并不会释放已有的资源

​	③ 不可剥夺条件：一个进程没有执行完毕的时候，不能强行剥夺条件

​	④ 循环等待： 若干进程形成了首尾相连的等待资源关系

死锁原因： 资源缺乏、进程顺序安排不合理等

2. **如何避免以及解决项目的死锁？**

   * 预防死锁： ①预先分配资源： 若进程有一个资源不满足，则不分配任何资源

     ​					② 有序分配资源：进程按照指定顺序获取资源

     A进程获取资源1，2，B进程也获取1，2

   * 避免死锁： 银行家算法

     如果存在一种进程执行顺序，按照此顺序可以保证所有进程都获得最大的资源需求，则认为系统是安全的

   * 死锁检测和恢复： 定时检测、进程执行缓慢检测、进程循环等待时检测

     ​					恢复：①抢占资源：从其他进程中抢占资源接触死锁

     ​								② 杀死进程接触死锁

     ​								③进程回退到某个某个接触死锁的节点
   
   * 具体策略根据具体的业务选择，数据库系统经常采用死锁检测和进程回退。
   
   * 如何检测：linux下通过pstack命令查看线程栈 + gdb，阻塞状态的则考虑是否死锁

---------

5. **操作系统如何接收鼠标的点击事件并转发？**

   os不直接与鼠标交互，鼠标点击后，鼠标驱动向操作系统发送信号，包括点击信息（左右键、位置信息等），操作系统将这个输入信号封装成消息发送给应用程序，应用程序内部循环检测os发送的消息，检测到消息后，查看位置信息，寻找对应的空间，调用其函数

### 4 锁专题

系统锁：

**基本锁**

| 类型   | 介绍                                                         |
| ------ | ------------------------------------------------------------ |
| 互斥锁 | 独占锁，加锁失败，进入阻塞态，加锁成功，进入就绪态，发生两次==内核上下文切换== |
| 自旋锁 | 加锁失败，进入==忙等待==，不需要进入内核态上下文切换         |

* 当可以判断 **加锁后进程的执行时间**小于 上下文切换时间，选择自旋锁，否则互斥锁

**高级锁**

| 类型   | 介绍                                                         |
| ------ | ------------------------------------------------------------ |
| 读写锁 | 读时共享，写时互斥                                           |
| 乐观锁 | 无锁机制，假设资源不会冲突，进行操作，之后在判断是否冲突，冲突后手动修改后提交（git） |
| 悲观锁 | 假设所有资源都会冲突，访问就要加锁（互斥锁、自旋锁、读写锁） |

mysql锁：

| 类型 | 介绍 |
| ---- | ---- |
|      |      |



### 5 孤儿进程、僵尸进程

unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。

这种机制就是: 在每个进程退出的时候**,内核释放该进程所有的资源**,包括打开的文件,占用的内存等。 但是仍然为其**保留一定的信息**(包括进程号,退出状态,运行时间t等)。直到父进程通**过wait / waitpid来取时才释放**。 但这样就导致了问题

**如果进程不调用wait / waitpid的话，** **那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免**

**孤儿进程**（没有危害）：

一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

**僵尸进程**（严重危害）：

一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

**守护进程**

独立于控制终端的孤儿进程，循环执行某任务，或者等待处理某个操作

**如何创建守护进程？**

1. 通过父进程创建子进程后，关闭父进程，子进程为孤儿进程，形式上脱离终端控制
2. 子进程中创建新会话，一个会话控制一个终端，真正独立于其他终端控制
3. （非必须）改变当前目录为根目录，防止占用文件系统资源
4. （非必须）关闭文件描述符，继承的打开文件不会用，占用资源
5. 执行守护进程的核心操作

**如何解决僵尸进程？**

（1）轮询挂起： ⽗进程通过 wait() 和 waitpid() 等函数等待⼦进程结束，但是，这会导致⽗进程挂起; 

（2）通过sigchild信号处理，当子进程结束时，操作系统会发送这个信号给父进程，以通知其子进程的状态变化（例如退出、停止或继续运行）

* 忽略信号：父进程对子进程退出状态不感兴趣，由内核回收
* 处理信号：在信号处理函数中调用wait回收子进程退出状态

```cpp
#include <signal.h>
#include <sys/types.h>
#include <sys/wait.h>
#include <unistd.h>

void sigchld_handler(int sig) {
    int status;
    pid_t pid;

    while ((pid = waitpid(-1, &status, WNOHANG)) > 0) {
        // 子进程退出处理
        printf("Child process %d terminated\n", pid);
    }
}

int main() {
    // 注册 SIGCHLD 信号处理器
    signal(SIGCHLD, sigchld_handler);

    if (fork() == 0) {
        // 子进程
        printf("Child process started\n");
        sleep(2);
        printf("Child process exiting\n");
        _exit(0);
    } else {
        // 父进程
        printf("Parent process waiting\n");
        while (1) {
            pause();  // 等待信号
        }
    }
}

```





## 2 虚拟地址、物理地址

### 1 虚拟内存

** 进程地址空间**

进程地址空间是进程PCB中的一个变量

通过mm_struct结构体进行管理

【为什么需要进程地址空间？】

1. 若进程直接访问物理内存，可能会发生越界访问，不安全
2. 地址空间的存在，可以更方便的进行进程与进程之间的数据代码解耦，保证进程之间的独立性
3. 编译器也会按照进程地址空间的规则对代码进行编译
4. cpu读取的指令的地址都是虚拟地址

![image-20240320173630091](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures@main/img/image-20240320173630091.png)



**作用**

在多进程环境下，使不同的内存地址不受影响，分配虚拟地址空间

物理内存只有一个，可能造成内存紧张，采用 **内存交换** 技术，将不常用的内存数据暂存在磁盘上

虚拟地址与物理地址的映射有两种 **分段**和 **分页**

|          | 分段                                | 分页                                   |
| -------- | ----------------------------------- | -------------------------------------- |
| 划分     | 基于逻辑，分为堆栈、bss data text段 | 虚拟地址和物理地址分为故固定大小页 4kb |
| 映射     | 基于段表（段起始物理地址+偏移量）   | 基于页表（虚拟地址 - 物理地址）        |
| 内存碎片 | 段大小不一致、外部碎片              | 内部碎片                               |
| 内存交换 | 段大小不一致，换入换出效率不高      | 交换部分页，效率高                     |
| 缓存技术 | \                                   | 局部性原理，TLB页表缓存，加快地址转换  |

**总结：虚拟内存的优势有哪些？**

1. 首先就是解决了多进程环境下的**进程地址冲突**问题，确保进程的独立安全
2. 操作系统可以通过页表对页设置 **属性权限**，比如读写权限，确保内存访问安全
3. 进程使用的虚拟地址远超物理地址，**基于局部性原理**，将不常用的内存数据换出磁盘上（磁盘swap上）

### 2 malloc

**2.1 两种内存分配方式**

* 当malloc空间小于128kb，从堆上申请，free 释放堆内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
* 当malloc空间大于128kb，从文件映射区申请，free 释放文件映射区内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

1. 通过brk()系统调用，从堆分配内存，brk指针向上移动

   <img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures@main/img/image-20240414170417942.png" alt="image-20240414170417942" style="zoom:50%;" />

   2. 通过mmap()系统调用，从文件映射区分配空间

      <img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures@main/img/image-20240414170533844.png" alt="image-20240414170533844" style="zoom:50%;" />

**2.2 为什么需要两种分配方式？**

完全使用mmap：从文件映射区分配内存，free完全释放内存， **在第一次访问虚拟地址时候发生缺页中断**，涉及到频繁的系统调用，需要进程在**用户态和内核态转换**，cpu开销大

结合使用brk，堆可以预先申请姣大的空间，内存申请和释放都在malloc的内存池中申请，**减少系统调用和缺页中断次数**



完全使用brk：malloc申请较大空间，后内存池变大，后续的小申请，会将内存池分割，导致碎片

因此，malloc申请过程中，大内存使用mmp，用完即释放，小内存使用brk，从内存池获取，减少系统调用



**2.3 free()传入地址，怎么知道释放多大的空间？**、

malloc申请地址的时候，会多申请16字节，用于存放申请的内存大小

free释放时候，向前便宜16字节，查询释放内存的大小

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202407221040090.png" alt="image-20240414173022765" style="zoom:50%;" />

**2.4 malloc（1）申请多少字节？**

系统中内存的申请释放以页为单位，申请一个字节时，根据编译器或者系统，给堆上申请一个页表大小，释放内存后，将申请的所有内存还给malloc内存池



**2.5 在4GB的物理内存上，申请8GB的内存会发生什么？**

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。

- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  - 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  
    
  
  - 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

### 3 改进lru算法

传统的 LRU 算法法无法避免下面这两个问题：

- 预读失效导致缓存命中率下降；
- 缓存污染导致缓存命中率下降；

为了避免「预读失效」造成的影响，Linux 和 MySQL 对传统的 LRU 链表做了改进：

- Linux 操作系统实现两个了 LRU 链表：**活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）**。
- MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**。

但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么**还存在缓存污染的问题**。

为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别提高了升级为热点数据的门槛：

- Linux 操作系统：在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。

- MySQL Innodb：在内存页被访问

  第二次

  的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行

  停留在 old 区域的时间判断

  ：

  - 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；
  - 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；

通过提高了进入 active list （或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。

# Redis

## 0 封装redis库

在C++中使用Redis作为缓存可以通过一些常用的Redis客户端库来实现。最常用的C++ Redis客户端库之一是 `hiredis`。`hiredis` 是一个简单高效的C Redis客户端，虽然它是用C写的，但可以很好地与C++结合使用。

首先，需要安装 `hiredis` 库。可以通过以下步骤进行安装：

```sh
sudo apt-get install libhiredis-dev
```

从源码编译安装

```sh
git clone https://github.com/redis/hiredis.git
cd hiredis
make
sudo make install
```

### 0.1 使用hiredis

下面是一个简单的C++示例，展示了如何使用`hiredis`与Redis进行交互：

```cpp
#include <iostream>
#include <hiredis/hiredis.h>

int main() {
    // 连接到Redis服务器
    redisContext* context = redisConnect("127.0.0.1", 6379);
    if (context == nullptr || context->err) {
        if (context) {
            std::cerr << "Connection error: " << context->errstr << std::endl;
            redisFree(context);
        } else {
            std::cerr << "Connection error: can't allocate redis context" << std::endl;
        }
        return 1;
    }

    // 设置一个键值对
    redisReply* reply = (redisReply*)redisCommand(context, "SET %s %s", "key", "value");
    std::cout << "SET: " << reply->str << std::endl;
    freeReplyObject(reply);

    // 获取一个键的值
    reply = (redisReply*)redisCommand(context, "GET %s", "key");
    if (reply->type == REDIS_REPLY_STRING) {
        std::cout << "GET: " << reply->str << std::endl;
    } else {
        std::cerr << "GET: failed" << std::endl;
    }
    freeReplyObject(reply);

    // 清除上下文
    redisFree(context);
    return 0;
}
```

### 0.2 现代C++封装hiredis

为了更好地与现代C++集成，可以对 `hiredis` 进行进一步封装，提供更方便的接口和异常处理。以下是一个简单的封装示例：

```cpp
#include <iostream>
#include <hiredis/hiredis.h>
#include <stdexcept>

class Redis {
public:
    Redis(const std::string& host, int port) {
        context = redisConnect(host.c_str(), port);
        if (context == nullptr || context->err) {
            if (context) {
                throw std::runtime_error(context->errstr);
            } else {
                throw std::runtime_error("Connection error: can't allocate redis context");
            }
        }
    }

    ~Redis() {
        if (context) {
            redisFree(context);
        }
    }

    void set(const std::string& key, const std::string& value) {
        redisReply* reply = (redisReply*)redisCommand(context, "SET %s %s", key.c_str(), value.c_str());
        if (reply == nullptr) {
            throw std::runtime_error("SET command failed");
        }
        freeReplyObject(reply);
    }

    std::string get(const std::string& key) {
        redisReply* reply = (redisReply*)redisCommand(context, "GET %s", key.c_str());
        if (reply == nullptr) {
            throw std::runtime_error("GET command failed");
        }
        std::string value;
        if (reply->type == REDIS_REPLY_STRING) {
            value = reply->str;
        } else {
            value = "";
        }
        freeReplyObject(reply);
        return value;
    }

private:
    redisContext* context;
};

int main() {
    try {
        Redis redis("127.0.0.1", 6379);
        redis.set("key", "value");
        std::string value = redis.get("key");
        std::cout << "GET: " << value << std::endl;
    } catch (const std::exception& e) {
        std::cerr << e.what() << std::endl;
    }
    return 0;
}
```

## 1. 数据结构

## 2. 单线程

## 3. 持久化

| 方法       | 具体                                                    | 优缺点                 |
| ---------- | ------------------------------------------------------- | ---------------------- |
| AOF日志    | 主线程进行，会阻塞下一个任务； 日志重写：fork子进程执行 | 丢失数据少、恢复速度慢 |
| RDB快照    | fork子进程中执行                                        | 恢复速度快，丢失数据多 |
| 混合持久化 | 在日志重写中，调用子进程写入快照到日志                  | 丢失速度少、恢复速度快 |

### 3.1 日志

#### 3.1.1 写回策略

命令执行成功 -> 写日志 -> 写入日志缓存区 -> 系统调用write() -> 内核缓冲区 -> 磁盘

| 策略     | 具体                                                         | 时机                                |
| -------- | ------------------------------------------------------------ | ----------------------------------- |
| always   | 执行一条语句，磁盘写入一条语句                               | 立刻调用`fsync()`，内核缓存写入磁盘 |
| everysec | 执行一条语句，写入内核缓冲区，内核一秒钟写入一次磁盘         | 异步任务调用`fsync()`               |
| no       | 执行一条语句，写入内核缓冲区，软件不控制写入，由内核自己抽时间写入磁盘 | 永不调用`fsync()`                   |

#### 3.1.2 日志重写

当日志文件过大，触发日志重写

![image-20240805102231944](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408051022212.png)

主进程：

1. 执行客户端命令
2. 执行后的命令写入日志缓冲区  -> write -> 内核缓冲区 -> 磁盘日志
3. 执行后的命令写入日志重写缓冲区

子进程：

1. 合并磁盘日志中的命令（此时主进程可能会再次添加日志）
2. 合并完毕，给主进程发送信号

主进程：

1. 根据重写缓冲区，追加日志



### 3.2 快照

* fork子进程，将当前数据（真实数据）写入磁盘
* 主进程，写时复制
* 磁盘中保存数据缓慢，若服务器宕机，丢失数据多

### 3.3 混合持久化

当开启了混合持久化时，在 ==AOF 重写日志==时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB快照 方式写入到 AOF 文件

然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件

写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件

最后，日志的前半部分是真实的快照数据，后半部分是追加的日志信息

<img src="https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408051044409.png" alt="image-20240805104418164" style="zoom:50%;" />

### 4. 大key数据的影响

![image-20240805110356492](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408051103740.png)

![image-20240805110417838](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408051104914.png)



## 4 淘汰策略

### 4.1 过期淘汰策略

1. 对一个key设置过期时间
2. 通过过期字典--哈希表（key， val过期事件）进行管理

| 策略     | 具体                                    | 优缺点                                   |
| -------- | --------------------------------------- | ---------------------------------------- |
| 定时淘汰 | 设置定时，到时间删除所有过期key         | 对cpu不友好，时间浪费在与当前key无关的事 |
| 惰性淘汰 | 每次redis访问key时，检查该key，过期删除 | 对内存不友好，只会删除当前过期key        |
| 定期淘汰 | 定时检查一部分key，删除过期             | 综合上述                                 |

* redis的过期淘汰策略   【惰性删除 + 定期删除】

1. 惰性删除：访问key，检查是否过期

2. 过期删除：**每秒10次检查数据库，每次随机检查20个key**

   ​		若有1/4过期，则再次检查20个key重复

   ​		默认超时时间25ms，退出



### 4.2 内存淘汰策略

1. 当redis占用内存到达设置的最大内存，触发内存淘汰策略

| 策略        | 具体                                                      | 优缺点                                    |
| ----------- | --------------------------------------------------------- | ----------------------------------------- |
| 不淘汰策略  | 到达最大内存后，无法再加入key，但可以访问                 |                                           |
| 淘汰策略    |                                                           |                                           |
| lru         | 链表保存数据，超时删除节点，访问移动到表头                | 1 链表空间开销 2 移动节点耗时             |
| allkeys-LRU | 添加字段：lru，记录最近访问时间                           | 1 节省空间 2不需要移动 3 无法解决缓存污染 |
| allkeys-LFU | 复用字段：lru，高字节记录最近访问时间，低字节记录访问频率 | 根据访问频率来淘汰内存                    |

注意：

* 缓存污染：一次读取大量数据，只会使用一次，但是会停留再redis很长时间，导致缓存命中率下降

## 5 主从复制

![image-20240806102708179](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408061027264.png)

1. 数据集中到一台服务器，可能导致数据丢失，恢复服务器时候，不能提供服务。
2. 将数据备份到多个服务器中，通过**主从复制，读写分离**来保证数据的一致性

主从复制的三种方法：

| 策略           | 使用阶段                                                     |
| -------------- | ------------------------------------------------------------ |
| 全量同步       | 第一次同步、断网后环形缓冲区（repl backlog buffer）被覆盖、replication buffer满了 |
| 长连接命令传播 | 第一次同步之后                                               |
| 增量同步       | 断网重连后，环形缓冲区未被覆盖                               |

### 5.1 全量复制

主服务器进程fork子进程异步进行全量复制。主服务器新接收的命令执行，将命令放入replication buffer。

全量复制：生成快照，将快照发给从服务器

从服务器清除自身的数据，加载快照文件，加载完毕后发送信号给主服务器

主服务器将replication buffer新命令，通过命令传播发送给从服务器

### 5.2 命令传播

![image-20240806095453250](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408060954552.png)

第一次同步，主服务器什么时候将新命令放入replication buffer？

* 主服务器生成快照期间
* 主服务器发送快照期间
* 从服务器加载快照期间

主服务器将replication buffer中的新命令，通过命令传播发送给从服务器

### 5.3 增量复制

在tcp断开恢复后，从服务器怎么保证数据一致性？

通过环形buffer控制

![image-20240806095623602](https://cdn.jsdelivr.net/gh/ZhangYuQiao326/study_nodes_pictures/img/202408060956877.png)

1. 主服务器同时向replication 和 环形buffer写入最新要同步的命令
2. 从服务器连接断开重连后，判断出要更新的数据仍旧在环形buffer内，则采用增量复制，将新数据写入replication buffer，发送给从服务器
3. 若环形buffer已经覆盖，则采用全量复制，fork进程进行快照，发送。

### 5.4 两个缓冲区

在 Redis 中，主服务器（Master）会为每个从服务器（Replica/Slave）维护一个单独的**复制缓冲区（Replication Buffer）**。

当从服务器初次连接到主服务器时，会进行一次全量同步（full synchronization）。主服务器会把当前的数据库快照（RDB文件）发送给从服务器，然后把在发送快照期间收到的所有写操作记录到复制缓冲区，并在快照发送完毕后将这些操作发送给从服务器。

在完成全量同步之后，从服务器会接收并应用复制缓冲区中的写操作

 **replication backlog积压缓冲区**是一个环形缓冲区，整个master进程中只会存在一个，所有的slave公用。

backlog的大小通过repl-backlog-size参数设置，默认大小是1M。

其大小可以根据每秒产生的命令 乘以（（master执行rdb bgsave的时间）+ (master发送rdb到slave的时间) + (slave load rdb文件的时间) ) ，来估算积压缓冲区的大小，repl-backlog-size值不小于这两者的乘积。

## 6 哨兵集群

--解决主节点故障

### 6.1 集群连接

1. 哨兵之间通过发布者-订阅者模式连接
2. 哨兵集群通过与主服务器节点通信，获得从服务器信息，与从服务器连接
3. 哨兵集群与客户端通过 发布者-订阅者模式连接，通知客户端信息

### 6.2 故障转移-二次投票

主节点出现故障，更换主节点

1. 哨兵向主从节点ping，发现主节点 **主观下线**，通知其他哨兵验证
2. 一次投票：票数超过指定的值（个数/2 + 1），确认主节点 **客观下线**
3. 二次投票：票数超过指定的值（个数/2 + 1）和 集群数的一半， 确认哨兵leader
4. 哨兵leader选择从节点（优先级->同步进度->节点序号）**变更为主节点**，其他从节点指向主节点
5. 哨兵leader通过 **发布者-订阅者模式** 通知客户端修改主节点ip
6. 继续监听宕机的原主节点，上线后，**变更为从节点**

## 7 缓存与消息队列

### 7.1 redis实现缓存

#### 7.1.1 存在问题

| 问题                 | 具体                                                         | 产生原因                               |
| -------------------- | ------------------------------------------------------------ | -------------------------------------- |
| 缓存雪崩             | redis中大量的数据同时过期，访问数据库，造成数据库压力过大宕机 | 1、大量数据同时过期、2、redis宕机      |
| 缓存击穿（雪崩子集） | redis中热点数据过期，访问数据库，高并发下造成数据库宕机      | 热点数据过期                           |
| 缓存穿透             | redis 和 数据库都没有所访问的数据                            | 1、业务失误删除数据库内容  2、黑客攻击 |

解决方式

| 问题                    | 解决                                                         |
| ----------------------- | ------------------------------------------------------------ |
| 大量数据同时过期        | 1、设置均匀过期时间   2、设置互斥锁，访问1次数据库，刷新redis  3、不设置过期时间，后台定时刷新缓存 |
| redis宕机               | 1、服务器熔断，禁止用户再次访问redis和数据库   2、哨兵集群，切换主从节点 |
| 热点数据过期            | 1、设置互斥锁  2、后台刷新缓存                               |
| redis和数据库中均无数据 | 1、验证查询数据是否非法  2、使用布隆过滤器查询缓存中数据是否存在 3、设置无查询数据返回null |

注：

1. 布隆过滤器：由一个位图和n个哈希函数构成

   插入数据时，通过n个哈希函数计算x为n个哈希值

   将位图中，以n个哈希值为下表的元素设置为1

   查询时候，若这n个位置均为1，则说明该数据存在缓存

   问题：其他数据也可能刚好这n个位置为1

#### 7.1.2 本地/redis缓存

| 本地缓存                             | redis缓存                                |
| ------------------------------------ | ---------------------------------------- |
| vector、list、unordered_map等        | redis                                    |
| 适合本地的小数据处理                 | 处理分布式大数据、持久化                 |
| 持久化困难，无法自动写入磁盘         | 可以持久化，自动写入磁盘                 |
| 不适合分布式系统                     | 支持分布式集群模式，通过哨兵模式保证安全 |
| 多线程中，需要同步机制实现缓存一致性 | 支持异步操作、发布订阅模式               |
|                                      |                                          |



### `vector`和`unordered_map`作为缓存

**优点**：
1. **低延迟**：由于数据保存在内存中，访问速度非常快，适用于需要快速读写的小规模数据集。
2. **简单性**：直接在代码中使用标准库容器，不需要额外的依赖或配置。
3. **本地性**：数据保存在应用程序的内存中，不需要网络通信。

**缺点**：
1. **容量有限**：受限于应用程序运行所在机器的内存大小，难以处理大规模数据。
2. **持久化困难**：在应用程序重启或崩溃时，内存中的数据会丢失。
3. **分布式支持差**：难以在多台机器之间共享数据，不适合分布式系统。
4. **缓存一致性**：在多线程环境中，需要额外的同步机制来保证缓存一致性，增加了复杂性。

### Redis作为缓存

**优点**：
1. **大容量**：可以处理大规模数据，支持将数据持久化到磁盘中，突破单机内存限制。
2. **持久化**：支持数据持久化（如RDB快照和AOF日志），在Redis服务器重启后数据仍然存在。
3. **分布式**：支持集群模式，可以在多台机器上分布式存储和访问数据。
4. **多种数据结构**：支持丰富的数据结构（如字符串、哈希、列表、集合、有序集合等），可以灵活应对各种应用场景。
5. **高可用**：支持主从复制和自动故障转移，提供高可用性和容灾能力。
6. **异步操作**：支持异步操作和发布/订阅模式，适合需要异步处理的场景。

**缺点**：
1. **网络延迟**：需要通过网络访问Redis服务器，可能会带来网络延迟。
2. **复杂性**：需要安装和配置Redis服务器，并在应用程序中集成相应的客户端库。
3. **维护成本**：需要独立的运维和监控Redis服务器，增加了系统复杂度和维护成本。

### 使用场景

**`vector`和`unordered_map`作为缓存适用场景**：
- 小规模数据集，数据量不会超过机器内存限制。
- 高速缓存，极低延迟要求。
- 简单应用，不需要持久化、不需要分布式支持。
- 单机应用，不需要跨服务器共享数据。

**Redis作为缓存适用场景**：
- 大规模数据集，数据量可能超过单机内存限制。
- 需要持久化的数据，避免数据在重启或崩溃时丢失。
- 分布式系统，需要在多台机器之间共享和访问数据。
- 需要高可用性和容灾能力的应用。
- 需要支持丰富的数据结构和复杂操作的应用。
- 

- **本地缓存**（如`vector`和`unordered_map`）适用于小规模、简单、高速的数据缓存需求。
- **Redis缓存**适用于大规模、复杂、高可用、分布式的数据缓存需求。



### 7.2 redis实现消息队列

使用Redis构建消息队列并通知另一个进程读取消息，可以使用Redis的发布/订阅（Pub/Sub）机制或列表（List）结合阻塞命令（如`BLPOP`）来实现。以下是两种方法的详细解释和示例代码：

#### 方法1：发布/订阅机制

发布/订阅机制允许一个进程发布消息，另一个进程订阅特定的频道，当有消息发布到该频道时，订阅者会收到通知。`hiredis`库可以用于实现这一机制。

**Publisher（发布者）**：

```cpp
#include <iostream>
#include <hiredis/hiredis.h>

void publishMessage(const std::string& channel, const std::string& message) {
    redisContext* context = redisConnect("127.0.0.1", 6379);
    if (context == nullptr || context->err) {
        if (context) {
            std::cerr << "Connection error: " << context->errstr << std::endl;
            redisFree(context);
        } else {
            std::cerr << "Connection error: can't allocate redis context" << std::endl;
        }
        return;
    }

    redisReply* reply = (redisReply*)redisCommand(context, "PUBLISH %s %s", channel.c_str(), message.c_str());
    if (reply == nullptr) {
        std::cerr << "Publish failed" << std::endl;
    } else {
        std::cout << "Message published to channel: " << channel << std::endl;
        freeReplyObject(reply);
    }

    redisFree(context);
}

int main() {
    publishMessage("my_channel", "Hello, World!");
    return 0;
}
```

**Subscriber（订阅者）**：

```cpp
#include <iostream>
#include <hiredis/hiredis.h>

void subscribeChannel(const std::string& channel) {
    redisContext* context = redisConnect("127.0.0.1", 6379);
    if (context == nullptr || context->err) {
        if (context) {
            std::cerr << "Connection error: " << context->errstr << std::endl;
            redisFree(context);
        } else {
            std::cerr << "Connection error: can't allocate redis context" << std::endl;
        }
        return;
    }

    redisReply* reply = (redisReply*)redisCommand(context, "SUBSCRIBE %s", channel.c_str());
    if (reply == nullptr) {
        std::cerr << "Subscribe failed" << std::endl;
    } else {
        freeReplyObject(reply);
    }

    while (redisGetReply(context, (void**)&reply) == REDIS_OK) {
        if (reply == nullptr) {
            continue;
        }

        if (reply->type == REDIS_REPLY_ARRAY && reply->elements == 3) {
            if (strcmp(reply->element[0]->str, "message") == 0) {
                std::cout << "Received message: " << reply->element[2]->str << std::endl;
            }
        }
        freeReplyObject(reply);
    }

    redisFree(context);
}

int main() {
    subscribeChannel("my_channel");
    return 0;
}
```

#### 方法2：阻塞列表

使用Redis的列表和`BLPOP`命令，可以实现简单的消息队列，当有消息到达时通知另一个进程读取消息。

**Producer（生产者）**：

```cpp
#include <iostream>
#include <hiredis/hiredis.h>

void pushMessage(const std::string& queue, const std::string& message) {
    redisContext* context = redisConnect("127.0.0.1", 6379);
    if (context == nullptr || context->err) {
        if (context) {
            std::cerr << "Connection error: " << context->errstr << std::endl;
            redisFree(context);
        } else {
            std::cerr << "Connection error: can't allocate redis context" << std::endl;
        }
        return;
    }

    redisReply* reply = (redisReply*)redisCommand(context, "LPUSH %s %s", queue.c_str(), message.c_str());
    if (reply == nullptr) {
        std::cerr << "LPUSH failed" << std::endl;
    } else {
        std::cout << "Message pushed to queue: " << queue << std::endl;
        freeReplyObject(reply);
    }

    redisFree(context);
}

int main() {
    pushMessage("my_queue", "Hello, World!");
    return 0;
}
```

**Consumer（消费者）**：

```cpp
#include <iostream>
#include <hiredis/hiredis.h>

void consumeMessage(const std::string& queue) {
    redisContext* context = redisConnect("127.0.0.1", 6379);
    if (context == nullptr || context->err) {
        if (context) {
            std::cerr << "Connection error: " << context->errstr << std::endl;
            redisFree(context);
        } else {
            std::cerr << "Connection error: can't allocate redis context" << std::endl;
        }
        return;
    }

    while (true) {
        redisReply* reply = (redisReply*)redisCommand(context, "BLPOP %s 0", queue.c_str());
        if (reply == nullptr) {
            std::cerr << "BLPOP failed" << std::endl;
            continue;
        }

        if (reply->type == REDIS_REPLY_ARRAY && reply->elements == 2) {
            std::cout << "Received message: " << reply->element[1]->str << std::endl;
        } else {
            std::cerr << "Unexpected reply type: " << reply->type << std::endl;
        }
        freeReplyObject(reply);
    }

    redisFree(context);
}

int main() {
    consumeMessage("my_queue");
    return 0;
}
```

- **发布/订阅（Pub/Sub）机制**适用于需要实时通知和消息广播的场景。发布者发布消息，所有订阅者都会收到消息。
- **阻塞列表（List）和`BLPOP`命令**适用于生产者-消费者模式。生产者将消息推送到队列中，消费者阻塞等待消息的到来。













# 面试

2024-4-7 qq浏览器客户端1面

1. tcp 和 udp区别

2. tcp如何保证其可靠性，比如说传输的包有序、是否丢失 （答了三握四挥，含有seq和ack，分片传输，丢失补发，拥塞控制、流量控制。。。知道的都说了）

3. tcp片丢失如何补发的？（自己挖坑自己跳，不会。。。）

4. 说一下拥塞控制、流量控制 （又挖坑了。。。还好提前复习了）

5. 如何保证http连接过程中断开了，重连后还能恢复到之前的位置

   比如：下载文件，网络断开，恢复后仍能继续下载而不是重新下载

   （瞎答了tcp连接时，客户端断开，服务器不发消息则不知道断开，把面试官整笑了）

   提示： http头中有字段来记录位置

6. 说一下虚拟内存和物理内存 （只说了进程地址空间。。。）

7. 虚拟内存的好处是什么？（扩充内存、进程安全、还不够。。。。。）

8. 进程地址空间各个段存放什么数据？

9. 进程通信。。。（说了信号量、管道等，还不够，忘了，说了解线程通信）

10. 进程和线程区别，为什么需要线程，好处是什么？（不知道，举了qq的例子。。。最终目的说了为了提高效率。。。）

11. 线程死锁、解决方式，着重问了”有序分配资源“，进程有序还是资源有序，都可

12. 数据库事务相关，场景：多线程访问数据库脏数据，  （完全不会。。。 用锁保证安全）

13. 场景：1亿条访问记录存磁盘，问如何找到访问最多topk个

    。。。。红黑树？  内存不够，无法加入树

    。。。。位图？  什么是位图？

    。。。。快排+topk？     。。。内存不够怎么快排

    答案： 将1亿条数据分块放入内存，分块进行哈希统计次数，通过topk查找最多k条记录

11 算法题： 有序的链表，删除重复的元素 1 2 33 4  ->  124

12 反问： 岗位对c++功底要求？ 答：岗位用c++和前端技术

​				  为什么面试不问c++？ 答：面试的简历可能有java、c++等，对语言不看重，后期快速学习，着重考察基本功

​				  对我不足建议？ 答：os、db、网络系统复习学习
